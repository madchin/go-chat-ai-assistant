package main

import (
        "context"
        "encoding/json"
        "fmt"
        "io"
	"os"
	"flag"
	"errors"
        "cloud.google.com/go/vertexai/genai"
)

func generateContentFromText(w io.Writer, projectID string) error {
        location := "us-central1"
        modelName := "gemini-1.5-flash-001"

        ctx := context.Background()
        client, err := genai.NewClient(ctx, projectID, location)
        if err != nil {
                return fmt.Errorf("error creating client: %w", err)
        }
        gemini := client.GenerativeModel(modelName)
        prompt := genai.Text(
                "What's a good name for a flower shop that specializes in selling bouquets of dried flowers?")

        resp, err := gemini.GenerateContent(ctx, prompt)
        if err != nil {
                return fmt.Errorf("error generating content: %w", err)
        }
        // See the JSON response in
        // https://pkg.go.dev/cloud.google.com/go/vertexai/genai#GenerateContentResponse.
        rb, err := json.MarshalIndent(resp, "", "  ")
        if err != nil {
                return fmt.Errorf("json.MarshalIndent: %w", err)
        }
        fmt.Fprintln(w, string(rb))
        return nil
}


// functionCallsBasic opens a chat session and sends 2 messages to the model:
// - first, to convert a text into a structured function call request
// - second, to convert a structured function call response into natural language
func functionCallsBasic(w io.Writer, projectID string) error {
        prompt := "What's the weather like in Boston?"
        location := "us-central1"
        modelName := "gemini-1.5-flash-001"
        ctx := context.Background()
        client, err := genai.NewClient(ctx, projectID, location)
        if err != nil {
                return fmt.Errorf("unable to create client: %w", err)
        }
        defer client.Close()

        model := client.GenerativeModel(modelName)

        // Build an OpenAPI schema, in memory
        params := &genai.Schema{
                Type: genai.TypeObject,
                Properties: map[string]*genai.Schema{
                        "location": {
                                Type:        genai.TypeString,
                                Description: "location",
                        },
                },
        }
        fundecl := &genai.FunctionDeclaration{
                Name:        "getCurrentWeather",
                Description: "Get the current weather in a given location",
                Parameters:  params,
        }
        model.Tools = []*genai.Tool{
                {FunctionDeclarations: []*genai.FunctionDeclaration{fundecl}},
        }

        chat := model.StartChat()

        fmt.Fprintf(w, "Question: %s\n", prompt)
        resp, err := chat.SendMessage(ctx, genai.Text(prompt))
        if err != nil {
                return err
        }
        if len(resp.Candidates) == 0 ||
                len(resp.Candidates[0].Content.Parts) == 0 {
                return errors.New("empty response from model")
        }

        // The model has returned a function call to the declared function `getCurrentWeather`
        // with a value for the argument `location`.
        jsondata, err := json.MarshalIndent(resp.Candidates[0].Content.Parts[0], "", "  ")
        if err != nil {
                return fmt.Errorf("json.MarshalIndent: %w", err)
        }
        fmt.Fprintf(w, "function call generated by the model:\n%s\n\n", string(jsondata))

        // Create a function call response, to simulate the result of a call to a
        // real service
        funresp := &genai.FunctionResponse{
                Name: "getCurrentWeather",
                Response: map[string]any{
                        "currentWeather": "sunny",
                },
        }
        jsondata, err = json.MarshalIndent(funresp, "", "  ")
        if err != nil {
                return fmt.Errorf("json.MarshalIndent: %w", err)
        }
        fmt.Fprintf(w, "function call response sent to the model:\n%s\n\n", string(jsondata))

        // And provide the function call response to the model
        resp, err = chat.SendMessage(ctx, funresp)
        if err != nil {
                return err
        }
        if len(resp.Candidates) == 0 ||
                len(resp.Candidates[0].Content.Parts) == 0 {
                return errors.New("empty response from model")
        }

        // The model has taken the function call response as input, and has
        // reformulated the response to the user.
        jsondata, err = json.MarshalIndent(resp.Candidates[0].Content.Parts[0], "", "  ")
        if err != nil {
                return fmt.Errorf("json.MarshalIndent: %w", err)
        }
        fmt.Fprintf(w, "Answer generated by the model:\n%s\n", string(jsondata))

        return nil
}



func main() {
	googleCloudProjectId := flag.String("project-id", "", "google cloud project id used for communication with Gemini AI model")
	flag.Parse()
	fmt.Printf("%s google cloud projec tid value ", googleCloudProjectId)
	if *googleCloudProjectId == "" {
		fmt.Println("In order to run POC chat model you need to specify, google cloud project id ")
		return
	}
	/*	
	err := generateContentFromText(os.Stdout, *googleCloudProjectId)
	if err != nil {
		fmt.Println("error occured %v", err)
	}
	*/
	err := functionCallsBasic(os.Stdout, *googleCloudProjectId)
	if err != nil {
		 fmt.Println("error occured %v", err)

	}
}
